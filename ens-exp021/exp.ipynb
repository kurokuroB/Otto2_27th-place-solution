{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "import pickle\n",
    "import os\n",
    "import gc\n",
    "import copy\n",
    "import time\n",
    "import joblib\n",
    "from pprint import pprint\n",
    "import random\n",
    "from collections import defaultdict, Counter\n",
    "from tqdm import tqdm\n",
    "import string\n",
    "from typing import List, Dict, Tuple\n",
    "import datetime\n",
    "from datetime import datetime, timedelta, timezone\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cudf\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import optuna\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "\n",
    "print(os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = \"\"  # コンペ用ディレクトリ\n",
    "OUTPUT_DIR = \"\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 理想時のcvを見ることができる。\n",
    "def calc_candidates_recall(candidates, label, type):\n",
    "    pred = candidates.groupby(\"session\").aid.apply(set)\n",
    "    pred = pred.reset_index()\n",
    "    gt = label[label[\"type\"] == type]\n",
    "\n",
    "    gt_pred = gt.merge(pred, on=\"session\", how=\"left\")\n",
    "\n",
    "    # negasamp後に、gtに紐づかないaidが出る可能性があるので、空のsetでfillna\n",
    "    gt_pred[\"aid\"] = gt_pred[\"aid\"].apply(lambda d: d if isinstance(d, set) else set())\n",
    "\n",
    "    gt_pred[\"hits\"] = gt_pred.apply(\n",
    "        lambda x: min(len(set(x[\"ground_truth\"]) & x[\"aid\"]), 20), axis=1\n",
    "    )\n",
    "    gt_pred[\"gt_count\"] = gt_pred.apply(\n",
    "        lambda x: min(len(x[\"ground_truth\"]), 20), axis=1\n",
    "    )\n",
    "    return gt_pred.hits.sum() / gt_pred.gt_count.sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cust_blend_test(row, W=[1, 1]):\n",
    "    # Create a list of all model predictions\n",
    "    REC = []\n",
    "    for i in range(len(W)):\n",
    "        if i == 0:\n",
    "            REC.append(row[\"labels\"].split())\n",
    "        else:\n",
    "            REC.append(row[f\"labels_{i}\"].split())\n",
    "\n",
    "    # Create a dictionary of items recommended.\n",
    "    # Assign a weight according the order of appearance and multiply by global weights\n",
    "    res = {}\n",
    "    for idx in range(len(REC)):\n",
    "        for n, v in enumerate(REC[idx]):\n",
    "            if v in res:\n",
    "                res[v] += W[idx] / (n + 1)\n",
    "            else:\n",
    "                res[v] = W[idx] / (n + 1)\n",
    "\n",
    "    # Sort dictionary by item weights\n",
    "    res = list(dict(sorted(res.items(), key=lambda item: -item[1])).keys())\n",
    "\n",
    "    return res[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs = []\n",
    "type_weight = {\n",
    "    # weights optimized by optuna\n",
    "    \"clicks\": [1],\n",
    "    \"carts\": [\n",
    "        0.5253236565057308,\n",
    "        0.5951928633820697,\n",
    "        0.801464605050116,\n",
    "        0.6243351208415832,\n",
    "        0.7585375306136606,\n",
    "    ],\n",
    "    \"orders\": [\n",
    "        0.3850340038357991,\n",
    "        0.6271924079206362,\n",
    "        0.8090807792929008,\n",
    "        0.8202925544168471,\n",
    "        0.016455787620324642,\n",
    "    ],\n",
    "}\n",
    "type_exp = {\n",
    "    \"clicks\": [136],\n",
    "    \"carts\": [119, 135, 136, 141, 143],\n",
    "    \"orders\": [119, 135, 136, 141, 143],\n",
    "}\n",
    "for type_ in [\"clicks\", \"carts\", \"orders\"]:\n",
    "    print(type_)\n",
    "    target_paths = [\n",
    "        f\"{ROOT}/data/output/exp/{exp}/test_{type_[:-1]}_top20_candidates.pkl\"\n",
    "        for exp in type_exp[type_]\n",
    "    ]\n",
    "\n",
    "    sub = None\n",
    "    for i, path in enumerate(target_paths):\n",
    "        print(i)\n",
    "        df = pd.read_pickle(path)\n",
    "        if i == 0:\n",
    "            sub = df\n",
    "        else:\n",
    "            sub = sub.merge(df, on=[\"session_type\"], how=\"left\", suffixes=(\"\", f\"_{i}\"))\n",
    "\n",
    "    sub[\"prediction\"] = sub.apply(cust_blend_test, W=type_weight[type_], axis=1)\n",
    "    sub = sub[[\"session_type\", \"prediction\"]]\n",
    "    sub[\"prediction\"] = sub[\"prediction\"].apply(lambda x: \" \".join(x))\n",
    "    sub = sub.rename(columns={\"prediction\": \"labels\"})\n",
    "\n",
    "    subs.append(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.concat(subs, ignore_index=True)\n",
    "sub.to_csv(f\"{OUTPUT_DIR}/submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 | packaged by conda-forge | (main, May 27 2022, 16:56:21) \n[GCC 10.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f708a36acfaef0acf74ccd43dfb58100269bf08fb79032a1e0a6f35bd9856f51"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
